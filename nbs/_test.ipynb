{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Results\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.utils import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import altair as alt\n",
    "import astropy.constants as const\n",
    "import vegafusion as vf\n",
    "vf.enable(row_limit = int(1e6))\n",
    "\n",
    "\n",
    "from ids_finder.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rpy2 in /Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages (3.5.14)\n",
      "Requirement already satisfied: rpy2-arrow in /Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages (0.0.8)\n",
      "Requirement already satisfied: cffi>=1.10.0 in /Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages (from rpy2) (1.15.1)\n",
      "Requirement already satisfied: jinja2 in /Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages (from rpy2) (3.1.2)\n",
      "Requirement already satisfied: tzlocal in /Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages (from rpy2) (5.0.1)\n",
      "Requirement already satisfied: pyarrow in /Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages (from rpy2-arrow) (13.0.0)\n",
      "Requirement already satisfied: pycparser in /Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages (from cffi>=1.10.0->rpy2) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages (from jinja2->rpy2) (2.1.3)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/zijin/mambaforge/envs/cool_planet/lib/python3.10/site-packages (from pyarrow->rpy2-arrow) (1.24.4)\n",
      "\u001b[33mDEPRECATION: unyt 2.8.0 has a non-standard dependency specifier numpy>=\"1.13.0\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of unyt or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rpy2 rpy2-arrow\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2_arrow.arrow as pyra\n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(ggplot2)\n",
    "library(ggpubr)\n",
    "library(viridis)\n",
    "\n",
    "library(glue)\n",
    "library(arrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: helper functions to convert between `python` and `R` dataframes\n",
    "\n",
    "base = importr('base')\n",
    "\n",
    "conv_pl = rpy2.robjects.conversion.Converter(\n",
    "    'Pandas to pyarrow',\n",
    "    template=pyra.converter)\n",
    "\n",
    "@conv_pl.py2rpy.register(pl.DataFrame)\n",
    "def py2rpy_pandas(dataf: pl.DataFrame):\n",
    "    pa_tbl = dataf.to_arrow()\n",
    "    return base.as_data_frame(pa_tbl)\n",
    "    # return pyra.converter.py2rpy(pa_tbl) # NOTE: not working for ggplot2\n",
    "\n",
    "conv_pl = rpy2.ipython.rmagic.converter + conv_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read candidates from files in current directory\n",
    "\n",
    "tau = timedelta(seconds=60)\n",
    "\n",
    "jno_fp = Path(f'../data/jno_candidates_tau_{tau.seconds}.parquet')\n",
    "thb_fp = Path(f'../data/thb_candidates_sw_tau_{tau.seconds}.parquet')\n",
    "\n",
    "\n",
    "jno_candidates = pl.scan_parquet(jno_fp).collect()\n",
    "thb_candidates = pl.scan_parquet(thb_fp).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "au_in_km = const.au.to(\"km\").value\n",
    "\n",
    "jno_dist_cols = [\"X\", \"Y\", \"Z\"]\n",
    "\n",
    "jno_candidates = jno_candidates.with_columns(\n",
    "    pl_norm(jno_dist_cols).alias(\"distance\"),\n",
    ").with_columns(\n",
    "    (pl.col([\"X\", \"distance\"]) / au_in_km).map_alias(lambda col: col+\"_in_AU\"),\n",
    ").sort(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Save the plot, if filename is provided\n",
    "save_plot <- function(filename = NULL) {\n",
    "  if (!is.null(filename)) {\n",
    "    ggsave(filename = glue(\"../images/{filename}.png\"))\n",
    "    ggsave(filename = glue(\"../images/{filename}.pdf\"))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magnetic field strength vs. distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "\n",
    "file = f\"../data/jno_*.parquet\"\n",
    "lazy_df = pl.scan_parquet(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "b_cols = [\"BX\", \"BY\", \"BZ\"]\n",
    "\n",
    "every = \"3d\"\n",
    "b_df = (\n",
    "    lazy_df.with_columns(\n",
    "        pl_norm(b_cols).alias(\"B\"),)\n",
    "    .sort(\"time\")\n",
    "    .group_by_dynamic(\"time\", every=every)\n",
    "    .agg(\n",
    "        pl.mean(\"B\").alias(\"B_mean\"),\n",
    "    )\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "alt.Chart(b_df).mark_line().encode(\n",
    "    x=\"time\",\n",
    "    y=\"B_mean\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "binwidth = 0.1\n",
    "\n",
    "b_df = (\n",
    "    lazy_df.with_columns(\n",
    "        (pl.col('X')/au_in_km / binwidth).floor().alias('bin_group_id').cast(pl.Int64),\n",
    "        pl_norm(b_cols).alias(\"B\"),\n",
    "    ).group_by(\"bin_group_id\").agg(\n",
    "        pl.mean(\"B\").alias(\"B_mean\"),\n",
    "    ).with_columns(\n",
    "        (pl.col(\"bin_group_id\") * binwidth).alias(\"binned_distance\"),\n",
    "    ).collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "\n",
    "alt.Chart(b_df).mark_line().encode(\n",
    "    x=alt.X(\"binned_distance\").title(\"Distance from Sun (AU)\"),\n",
    "    y=alt.Y(\"B_mean\").title(\"Magnetic Field Strength (nT)\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance and Occurrence rates versus time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%markdown\n",
    "properties = {'width': 900, 'height': 150}\n",
    "\n",
    "chart1 = alt.Chart(candidates_pl).mark_point().encode(\n",
    "    x=alt.X('yearmonthdate(time)').axis(labels=False, title=None),\n",
    "    y=alt.Y('mean(distance_in_AU)').axis(title='Distance (AU)'),\n",
    ").properties(**properties)\n",
    "\n",
    "chart2 = alt.Chart(candidates_pl).mark_point().encode(\n",
    "    x='yearmonth(time)',\n",
    "    y='count()',\n",
    "    color = 'type',\n",
    "    row='type'\n",
    ").properties(**properties)\n",
    "\n",
    "chart1 & chart2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i jno_candidates -c conv_pl\n",
    "\n",
    "p <- ggplot(jno_candidates, aes(x = time, y = distance_in_AU)) + \n",
    "  geom_point() + # Plot distance by date\n",
    "  labs(x = \"Date\", y = \"Distance (AU)\") +\n",
    "  theme_pubr(base_size = 16) + \n",
    "  theme(aspect.ratio=0.25)\n",
    "\n",
    "print(p)\n",
    "\n",
    "# save_plot(filename = \"distance_by_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following codes deal with data gap better by filling the gap with the `null` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "every = pd.Timedelta(\"3d\")\n",
    "base_amplification_factor = every / pd.Timedelta(\"1d\")\n",
    "\n",
    "temp_df = (\n",
    "    jno_candidates.filter(\n",
    "        pl.col(\"time\") < pd.Timestamp(\"2016-05-01\") # There is a sudden increase in the number of TD candidates after this date\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"time\").dt.truncate(every).alias(\"truncated_time\")\n",
    "    )\n",
    "    .group_by(\"truncated_time\")\n",
    "    .agg(\n",
    "        pl.count()/base_amplification_factor,\n",
    "        pl.mean(\"distance_in_AU\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "df = temp_df.upsample(\"truncated_time\", every=every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i df -c conv_pl\n",
    "\n",
    "df$date <- as.Date(df$truncated_time)\n",
    "p1 <- ggplot(df, aes(x = date, y = distance_in_AU)) + \n",
    "  geom_line() + # Plot distance by date\n",
    "  labs(x = \"Date\", y = \"Distance (AU)\") +\n",
    "  theme_pubr(base_size = 16) + \n",
    "  theme(aspect.ratio=0.25)\n",
    "  \n",
    "p2 <- ggplot(df, aes(x = date, y = count)) + \n",
    "  geom_line() + # Plot distance by date\n",
    "  labs(x = \"Date\", y = \"Occurrence Rates (#/day)\") +\n",
    "  theme_pubr(base_size = 16) + \n",
    "  theme(aspect.ratio=0.25)\n",
    "\n",
    "p <- ggarrange(p1, p2, nrow = 2)\n",
    "\n",
    "filename <- \"distance_and_or\"\n",
    "# ggsave(glue(\"../images/{filename}.png\"))\n",
    "# ggsave(glue(\"../images/{filename}.pdf\"))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occurrence rates versus time of different types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the occurernce rate of each type of IDs as a function of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "plot_count_raw <- function(data, bin_width = 5) {\n",
    "  # Transform date column\n",
    "  data$date_only <- as.Date(data$time)\n",
    "  \n",
    "  # Plot\n",
    "  p <- ggplot(data, aes(x = date_only)) + \n",
    "    geom_freqpoly(binwidth = bin_width) + # Overall frequency by day\n",
    "    geom_freqpoly(aes(color = type), binwidth = bin_width) + # Frequency by day split by type\n",
    "    labs(x = \"Date\") +\n",
    "    theme_pubr(base_size = 16) +\n",
    "    theme(aspect.ratio=0.25)\n",
    "  \n",
    "  # Print the plot\n",
    "  print(p)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i thb_candidates -c conv_pl\n",
    "plot_count_raw(thb_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i jno_candidates -c conv_pl\n",
    "plot_count_raw(jno_candidates)\n",
    "\n",
    "filename <- \"jno_count_raw\"\n",
    "# ggsave(glue(\"../images/{filename}.png\"))\n",
    "# ggsave(glue(\"../images/{filename}.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see different types of IDs have different Occurrence rates. To demonstrate their relative change, amplify TD-like IDs by 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "def get_count_by_type(candidates: pl.DataFrame, truncation_delta=\"5d\"):\n",
    "    every = pd.Timedelta(truncation_delta)\n",
    "    base_amplification_factor = every / pd.Timedelta(\"1d\")\n",
    "    amplification_factors = {\n",
    "        \"RD\": 1 / base_amplification_factor,\n",
    "        \"ED\": 1 / base_amplification_factor,\n",
    "        \"TD\": 10 / base_amplification_factor,\n",
    "        \"ND\": 10 / base_amplification_factor,\n",
    "    }\n",
    "\n",
    "    temp_df = (\n",
    "        candidates.with_columns(\n",
    "            pl.col(\"time\").dt.truncate(every).alias(\"truncated_time\")\n",
    "        )\n",
    "        .group_by(\"truncated_time\", \"type\")\n",
    "        .agg(\n",
    "            pl.count(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    type_dfs = []\n",
    "    for type, group in temp_df.group_by(\"type\"):\n",
    "        type_df = (\n",
    "            group.sort(\"truncated_time\")\n",
    "            .upsample(\"truncated_time\", every=every)\n",
    "            .with_columns(\n",
    "                pl.col(\"type\").fill_null(type),\n",
    "                (pl.col(\"count\") * amplification_factors[type]),\n",
    "            )\n",
    "        )\n",
    "        type_dfs.append(type_df)\n",
    "\n",
    "    df = pl.concat(type_dfs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "plot_count_am <- function(df) {\n",
    "  tmp <- df %>%\n",
    "    mutate(name2=type)\n",
    "  tmp$date <- as.Date(tmp$truncated_time)\n",
    "  tmp$type <- factor(tmp$type, levels = c(\"RD\", \"ED\", \"TD\", \"ND\"))\n",
    "\n",
    "  p <- tmp %>%\n",
    "    ggplot( aes(date, count)) +\n",
    "      geom_line( data=tmp %>% dplyr::select(-type), aes(group=name2), color=\"grey\", linewidth=0.5, alpha=0.5) +\n",
    "      geom_line( aes(color=type), color=\"#69b3a2\")+\n",
    "      facet_grid(type ~ .) +\n",
    "      labs(x = \"Date\", y = \"Occurrence Rates (#/day)\") +\n",
    "      theme_pubr(base_size = 16) +\n",
    "      theme(aspect.ratio=0.25)\n",
    "\n",
    "  # Print the plot\n",
    "  print(p)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with appropriate arguments\n",
    "jno_count_df = get_count_by_type(\n",
    "    jno_candidates\n",
    "    .filter(pl.col(\"time\") < pd.Timestamp(\"2016-05-01\")) # There is a sudden increase in the number of TD candidates after this date\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i jno_count_df -c conv_pl\n",
    "plot_count_am(jno_count_df)\n",
    "# save_plot('jno_count_am')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thb_count_df = get_count_by_type(\n",
    "    thb_candidates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i thb_count_df -c conv_pl\n",
    "plot_count_am(thb_count_df)\n",
    "# save_plot('thb_count_am')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Occurrence rates (not normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jno_candidates_rd_like = jno_candidates.filter(\n",
    "    (pl.col(\"type\") == \"RD\") | (pl.col(\"type\") == \"ED\")\n",
    ")\n",
    "\n",
    "jno_candidates_td_like = jno_candidates.filter(\n",
    "    (pl.col(\"type\") == \"TD\") | (pl.col(\"type\") == \"ND\")\n",
    ")\n",
    "\n",
    "thb_candidates_rd_like = thb_candidates.filter(\n",
    "    (pl.col(\"type\") == \"RD\") | (pl.col(\"type\") == \"ED\")\n",
    ")\n",
    "\n",
    "thb_candidates_td_like = thb_candidates.filter(\n",
    "    (pl.col(\"type\") == \"TD\") | (pl.col(\"type\") == \"ND\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -i jno_candidates -c conv_pl\n",
    "%R -i jno_candidates_rd_like -c conv_pl\n",
    "%R -i jno_candidates_td_like -c conv_pl\n",
    "%R -i thb_candidates -c conv_pl\n",
    "%R -i thb_candidates_rd_like -c conv_pl\n",
    "%R -i thb_candidates_td_like -c conv_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "p1 <- gghistogram(jno_candidates, x = \"time\",\n",
    "   rug = TRUE,\n",
    "   color = \"type\", fill = \"type\",\n",
    "   )\n",
    "\n",
    "p2 <- gghistogram(jno_candidates_rd_like, x = \"time\",\n",
    "   rug = TRUE,\n",
    "   color = \"type\", fill = \"type\",\n",
    "   )\n",
    "\n",
    "p3 <- gghistogram(jno_candidates_td_like, x = \"time\",\n",
    "   rug = TRUE,\n",
    "   color = \"type\", fill = \"type\",\n",
    "   )\n",
    "\n",
    "p <- ggarrange(p1, p2, p3, nrow = 3)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "p1 <- gghistogram(thb_candidates, x = \"time\",\n",
    "   rug = TRUE,\n",
    "   color = \"type\", fill = \"type\",\n",
    "   )\n",
    "\n",
    "p2 <- gghistogram(thb_candidates_rd_like, x = \"time\",\n",
    "   rug = TRUE,\n",
    "   color = \"type\", fill = \"type\",\n",
    "   )\n",
    "\n",
    "p3 <- gghistogram(thb_candidates_td_like, x = \"time\",\n",
    "   rug = TRUE,\n",
    "   color = \"type\", fill = \"type\",\n",
    "   )\n",
    "\n",
    "p <- ggarrange(p1, p2, p3, nrow = 3)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of Occurrence rates (normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat = 'thb'\n",
    "files = f\"../data/{sat}_data_sw.parquet\"\n",
    "\n",
    "data = pl.scan_parquet(files).set_sorted('time').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_resolution = timedelta(minutes=1)\n",
    "l_resolution = timedelta(days=30)\n",
    "\n",
    "duration_df = data.group_by_dynamic(\n",
    "    'time', every = s_resolution\n",
    ").agg(\n",
    "    pl.lit(1).alias('availablity')\n",
    ").upsample(\n",
    "    'time', every= s_resolution\n",
    ").group_by_dynamic(\n",
    "    'time', every=l_resolution\n",
    ").agg(\n",
    "    (pl.sum('availablity') * s_resolution / l_resolution).alias('duration_ratio')\n",
    ")\n",
    "\n",
    "thb_count_df = get_count_by_type(\n",
    "    thb_candidates, l_resolution\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thb_count_normalized_df = thb_count_df.join(duration_df, left_on='truncated_time', right_on='time').with_columns(\n",
    "    (pl.col('count') / pl.col('duration_ratio')).alias('count')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i thb_count_normalized_df -c conv_pl\n",
    "plot_count_am(thb_count_normalized_df)\n",
    "# save_plot('thb_count_am')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occurrence rates versus distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_candidates_pl = jno_candidates.filter(\n",
    "    pl.col(\"time\") > pd.Timestamp(\"2013-06-01\")  # Where distance increases singularly\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i temp_candidates_pl -c conv_pl\n",
    "gghistogram(temp_candidates_pl, x=\"distance_in_AU\", rug=TRUE, color=\"type\", fill=\"type\", binwidth=0.1) + \n",
    "  labs(x=\"Distance (AU)\", y=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jno_candidates_rd_like = temp_candidates_pl.filter(  \n",
    "    (pl.col(\"type\") == \"RD\") | (pl.col(\"type\") == \"ED\")\n",
    ")\n",
    "\n",
    "jno_candidates_td_like = temp_candidates_pl.filter(\n",
    "    (pl.col(\"type\") == \"TD\") | (pl.col(\"type\") == \"ND\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i candidates_rd_like -c conv_pl\n",
    "\n",
    "gghistogram(candidates_rd_like, x=\"distance_in_AU\", rug=TRUE, color=\"type\", fill=\"type\", binwidth=0.1) + \n",
    "  labs(x=\"Distance (AU)\", y=\"Count\") +\n",
    "  theme_pubr(base_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i candidates_td_like -c conv_pl\n",
    "\n",
    "gghistogram(candidates_td_like, x=\"distance_in_AU\", rug=TRUE, color=\"type\", fill=\"type\", binwidth=0.1) + \n",
    "  labs(x=\"Distance (AU)\", y=\"Count\") +\n",
    "  theme_pubr(base_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binwidth = 0.1\n",
    "temp_df = temp_candidates_pl.with_columns(\n",
    "    (pl.col('distance_in_AU')/binwidth).floor().alias('bin_group_id').cast(pl.Int64),\n",
    ").group_by(\"bin_group_id\",'type').agg(\n",
    "    (pl.max(\"time\") - pl.min(\"time\")).alias(\"duration\"),\n",
    "    pl.col('distance_in_AU').mean().alias(\"mean_distance\"),\n",
    "    pl.count()\n",
    ").with_columns(\n",
    "    (pl.col(\"duration\") / pd.Timedelta(hours=24)).alias(\"duration_in_days\"),\n",
    ").filter(\n",
    "    pl.col(\"duration_in_days\") > 1 # filter out candidates that occur within 1 day\n",
    ").with_columns(\n",
    "    (pl.col(\"count\") / pl.col(\"duration_in_days\")).alias(\"occurrence_rate\")\n",
    ").sort(\n",
    "    \"bin_group_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pl.DataFrame({'bin_group_id': pl.arange(temp_df['bin_group_id'].min(), temp_df['bin_group_id'].max()+1, eager=True)})\n",
    "\n",
    "type_dfs = []\n",
    "for type, jno_fp in temp_df.group_by(\"type\"):\n",
    "    type_df = _.join(jno_fp, on=\"bin_group_id\", how=\"left\").with_columns(\n",
    "            pl.col(\"type\").fill_null(type),\n",
    "        )\n",
    "    type_dfs.append(type_df)\n",
    "\n",
    "or_df = pl.concat(type_dfs).with_columns(\n",
    "    (pl.col(\"bin_group_id\") * binwidth).alias(\"binned_distance\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i or_df -c conv_pl\n",
    "p <- ggplot(or_df, aes(x=binned_distance, y=occurrence_rate, color=type)) +\n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    labs(x=\"Distance from the Sun (AU)\", y=\"Occurrence rate (per day)\", color=\"Type\") +\n",
    "    theme_pubr(base_size = 16)\n",
    "    \n",
    "filename <- \"or_by_distance\"\n",
    "ggsave(glue(\"images/{filename}.png\"))\n",
    "ggsave(glue(\"images/{filename}.pdf\"))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jno_candidates_rd_like = or_df.filter(\n",
    "    (pl.col(\"type\") == \"RD\") | (pl.col(\"type\") == \"ED\")\n",
    ")\n",
    "\n",
    "jno_candidates_td_like = or_df.filter(\n",
    "    (pl.col(\"type\") == \"TD\") | (pl.col(\"type\") == \"ND\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i candidates_rd_like -c conv_pl\n",
    "p <- ggplot(candidates_rd_like, aes(x=binned_distance, y=occurrence_rate, color=type)) +\n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    labs(x=\"Distance from the Sun (AU)\", y=\"Occurrence rate (per day)\", color=\"Type\") +\n",
    "    theme_pubr(base_size = 16)\n",
    "    \n",
    "filename <- \"or_by_distance_rd\"\n",
    "ggsave(glue(\"images/{filename}.png\"))\n",
    "ggsave(glue(\"images/{filename}.pdf\"))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i candidates_td_like -c conv_pl\n",
    "p <- ggplot(candidates_td_like, aes(x=binned_distance, y=occurrence_rate, color=type)) +\n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    labs(x=\"Distance from the Sun (AU)\", y=\"Occurrence rate (per day)\", color=\"Type\") +\n",
    "    theme_pubr(base_size = 16)\n",
    "    \n",
    "filename <- \"or_by_distance_td\"\n",
    "ggsave(glue(\"images/{filename}.png\"))\n",
    "ggsave(glue(\"images/{filename}.pdf\"))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i candidates_rd_like -c conv_pl\n",
    "p <- ggscatter(candidates_rd_like, x = \"mean_distance\", y = \"occurrence_rate\",\n",
    "        color = \"type\",\n",
    "        add = \"loess\",  # Add regressin line\n",
    "        add.params = list(fill = \"lightgray\"), # Customize reg. line\n",
    "        shape = 21, size=3, # Points color, shape and size\n",
    "        conf.int = TRUE, # Add confidence interval\n",
    "        cor.coef = TRUE, # Add correlation coefficient. see ?stat_cor\n",
    "        cor.coeff.args = list(method = \"pearson\", label.x = 3, label.sep = \"\\n\")\n",
    "    ) + \n",
    "    labs(x=\"Distance from the Sun (AU)\", y=\"Occurrence rate (per day)\", color=\"Type\") +\n",
    "    theme_pubr(base_size = 16)\n",
    "    \n",
    "filename <- \"or_by_distance_rd\"\n",
    "ggsave(glue(\"images/{filename}.png\"))\n",
    "ggsave(glue(\"images/{filename}.pdf\"))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i candidates_td_like -c conv_pl\n",
    "p <- ggscatter(candidates_td_like, x = \"mean_distance\", y = \"occurrence_rate\",\n",
    "        color = \"type\",\n",
    "        add = \"loess\",  # Add regressin line\n",
    "        add.params = list(fill = \"lightgray\"), # Customize reg. line\n",
    "        shape = 21, size=3, # Points color, shape and size\n",
    "        conf.int = TRUE, # Add confidence interval\n",
    "        cor.coef = TRUE, # Add correlation coefficient. see ?stat_cor\n",
    "        cor.coeff.args = list(method = \"pearson\", label.x = 3, label.sep = \"\\n\")\n",
    "    ) + \n",
    "    labs(x=\"Distance from the Sun (AU)\", y=\"Occurrence rate (per day)\", color=\"Type\") +\n",
    "    theme_pubr(base_size = 16)\n",
    "    \n",
    "filename <- \"or_by_distance_td_fit\"\n",
    "ggsave(glue(\"images/{filename}.png\"))\n",
    "ggsave(glue(\"images/{filename}.pdf\"))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting candidates of different types of discontinuities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(candidates).mark_point().encode(\n",
    "#     x='yearmonth(time)',\n",
    "#     y='count()',\n",
    "#     color='type',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(jno_candidates.to_pandas()).mark_point().encode(\n",
    "    x='X',\n",
    "    y='count(type)',\n",
    "    color='type',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candidates(jno_candidates, candidate_type='TD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candidates(jno_candidates, candidate_type='RD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candidates(jno_candidates, candidate_type='ED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candidates(jno_candidates, candidate_type='ND')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occurrence rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Occurrence rates of different types of ID\n",
    "def Occurrence_rate(candidates, candidate_type):\n",
    "    return len(candidates[candidates['type'] == candidate_type]) / len(candidates)\n",
    "\n",
    "def time_Occurrence_rate(candidates):\n",
    "    if len(candidates) <= 1:\n",
    "        return None\n",
    "    else:\n",
    "        return (candidates.iloc[-1]['tstop'] - candidates.iloc[0]['tstart']) / (len(candidates) -1)\n",
    "\n",
    "CANDIDATE_TYPES = ['RD', 'TD', 'ED', 'ND']\n",
    "\n",
    "for candidate_type in CANDIDATE_TYPES:\n",
    "    logger.info(f\"Occurrence rate of {candidate_type}: {Occurrence_rate(jno_candidates, candidate_type)}\")\n",
    "    logger.info(f\"Time Occurrence rate of {candidate_type}: {time_Occurrence_rate(jno_candidates[jno_candidates['type'] == candidate_type])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp.ColByFrameFunc(\"R\", lambda df: df[['X','Y', 'Z']].apply(np.linalg.norm, axis=1), func_desc='calculating R')(jno_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jno_candidates.plot(x=\"X\", y=\"d_star\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates.update(pdp_calibrate_duration.apply(temp_candidates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_candidates = get_candidates(jno_candidates, 'RD')\n",
    "temp_candidates = pdp_calc_duration(temp_candidates)\n",
    "temp_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candidates(temp_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RD paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUG: `Bm0` may be larger than `radius`\n",
    "\n",
    "def calculate_RD_parameter(Bl, Bm, Bn=None, num_avg_points=8):\n",
    "    \"\"\"Calculate magnetic field parameters for rotation discontinuity (RD) identification.\n",
    "\n",
    "    Args:\n",
    "        Bl (xarray.DataArray): 'Bl' component of the magnetic field.\n",
    "        Bm (xarray.DataArray): 'Bm' component of the magnetic field.\n",
    "         Bn (xarray.DataArray, optional): 'Bn' component of the magnetic field. Defaults to None.\n",
    "        num_avg_points (int): Number of points at the start and end of data for averaging.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing 'Bl_max' and 'Bm0', and 'Bn0' if 'Bn' was provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    radius = np.sqrt(Bl**2 + Bm**2).mean(dim=\"time\")\n",
    "\n",
    "    # Calculate 'Bm0'\n",
    "    Bm_start = Bm[:num_avg_points].mean(dim=\"time\")\n",
    "    Bm_end = Bm[-num_avg_points:].mean(dim=\"time\")\n",
    "    Bm0 = (Bm_start + Bm_end) / 2\n",
    "    \n",
    "    # Calculate 'Bl_max': average of the absolute values of 'Bl' at the start and end of the data\n",
    "    # Bl_start = Bl[:num_avg_points].mean(dim=\"time\")\n",
    "    # Bl_end = Bl[-num_avg_points:].mean(dim=\"time\")\n",
    "    # Bl_max = (np.abs(Bl_start) + np.abs(Bl_end)) / 2\n",
    "    \n",
    "    # Calculate 'Bl_max': using radius, more reliable\n",
    "    Bl_max = np.sqrt(radius**2 - Bm0**2)\n",
    "\n",
    "    # Calculate 'Bn0' if 'Bn' is provided, else return 'Bl_max' and 'Bm0' only\n",
    "    if Bn is not None:\n",
    "        Bn0 = Bn.mean(dim=\"time\")\n",
    "        return Bl_max.values, Bm0.values, Bn0.values\n",
    "\n",
    "    return Bl_max.values, Bm0.values\n",
    "\n",
    "\n",
    "def RD_parameter(data, tstart, tstop):\n",
    "    mva(data, tstart, tstop)\n",
    "    mva_data = get_data(\"fgm_rot\", xarray=True)\n",
    "        \n",
    "    Bl = mva_data.sel(v_dim=0)\n",
    "    Bm = mva_data.sel(v_dim=1)\n",
    "    Bn = mva_data.sel(v_dim=2)\n",
    "\n",
    "    Bl_max, Bm0, Bn0 = calculate_RD_parameter(Bl, Bm, Bn)\n",
    "    return pd.Series({\n",
    "        'Bl_max':Bl_max, \n",
    "        'Bm0': Bm0, \n",
    "        'Bn0': Bn0\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp.ApplyToRows(lambda row: RD_parameter(juno_fgm_b, row['tstart'], row['tstop']), func_desc='calculating parameters for RD')(jno_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$PVI(t) = B(t + \\tau/2) - B(t - \\tau/2) = B_+(t) - B_-(t)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration_TD(vec: xr.DataArray, threshold_ratio=0.2) -> pd.Series:\n",
    "    # Calculate magnitude and its difference\n",
    "    vec_mag = calc_vec_mag(vec)\n",
    "    vec_mag_diff = vec_mag.differentiate(\"time\")\n",
    "\n",
    "    # Determine if the trend is increasing or decreasing\n",
    "    increasing = vec_mag[0] < vec_mag[-1]\n",
    "\n",
    "    # Determine d_star based on trend\n",
    "    d_star_index = vec_mag_diff.argmax(dim=\"time\").values if increasing else vec_mag_diff.argmin(dim=\"time\").values\n",
    "    d_star = vec_mag_diff[d_star_index].values\n",
    "    d_star_time = vec_mag_diff.time[d_star_index].values\n",
    "    \n",
    "    threshold = d_star * threshold_ratio\n",
    "\n",
    "    # Determine start time\n",
    "    pre_vec_mag = vec_mag_diff[0:d_star_index]\n",
    "    condition = pre_vec_mag > threshold if increasing else pre_vec_mag < threshold\n",
    "    start_index = np.where(condition)[0][0]\n",
    "    start_time = pre_vec_mag.time[start_index].values\n",
    "    logger.debug(f'start_index: {start_index}, start_time: {start_time}')\n",
    "\n",
    "    # Determine stop time\n",
    "    post_vec_mag = vec_mag_diff[d_star_index:]\n",
    "    condition = post_vec_mag > threshold if increasing else post_vec_mag < threshold\n",
    "    end_index = np.where(condition)[0][-1]\n",
    "    end_time = post_vec_mag.time[end_index].values\n",
    "\n",
    "    return pd.Series({\n",
    "        'TD_type': \"increasing\" if increasing else \"decreasing\",\n",
    "        'TD_d_star': d_star,\n",
    "        'TD_star_time': d_star_time,\n",
    "        'TD_start': start_time,\n",
    "        'TD_stop': end_time,\n",
    "    })\n",
    "\n",
    "pdp_TD = pdp.PdPipeline([\n",
    "    pdp.ApplyToRows(lambda candidate: duration_TD(get_candidate_data_xr(candidate)) if candidate['type']=='TD' else None, func_desc='calculating duration parameters of TD'),\n",
    "])\n",
    "\n",
    "# duration_TD(get_candidate_data(TD_candidates.sample().iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD_candidates = pdp_TD(TD_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_candidates(TD_candidates, plot_func=plot_TD_candidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obsolete codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: calculate the PVI series for a given time series\n",
    "def calculate_PVI_xr(vec: xr.DataArray, tau, resample_frequency = None, interval_of_averaging=None):\n",
    "    \"\"\"\n",
    "    This function calculates the Partial Variance of Increments (PVI) series for a given time series.\n",
    "\n",
    "    Parameters:\n",
    "    vec (xr.DataArray): The input time series with two dimensions `time` and `v_dim`.\n",
    "    tau (int): The time lag, in unit `s`,typically selected to lie in the inertial range of the fluctuations.\n",
    "    resample_frequency (int): The resample frequency, in unit `s`. If None, defaults to tau.\n",
    "    interval_of_averaging (int): The number of samples over which to compute the trailing average. It's often chosen to be comparable to, or greater than, a correlation length (or time) of the signal.\n",
    "\n",
    "    Returns:\n",
    "    PVI_series (np.array): The resulting PVI series.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample the vector at the given time lag (tau)\n",
    "    # vec_sampled = vec.resample(time=tau).mean(dim='time')\n",
    "    if resample_frequency is None:\n",
    "        resample_frequency = tau\n",
    "\n",
    "    # Interpolate to a regular time grid\n",
    "    vec_sampled = vec.resample(time=pd.Timedelta(resample_frequency, unit='s')).interpolate('linear')\n",
    "    \n",
    "    # Note: Xarray enforces alignment between index Coordinates (that is, coordinates with the same name as a dimension, marked by *) on objects used in binary operations.\n",
    "    vec_plus = vec_sampled.assign_coords({'time': vec_sampled['time'] - pd.Timedelta(tau/2, unit='s')})\n",
    "    vec_minus = vec_sampled.assign_coords({'time': vec_sampled['time'] + pd.Timedelta(tau/2, unit='s')})\n",
    "    increments  = vec_plus - vec_minus\n",
    "\n",
    "    # Calculate the magnitudes of these increments\n",
    "    mag_increments = linalg.norm(increments, dims='v_dim')\n",
    "    # logger.info(f\"Magnitude of increments: {mag_increments}\")\n",
    "\n",
    "    # Square the magnitudes of the increments, and compute a moving average over the specified interval\n",
    "    if interval_of_averaging is None:\n",
    "        normalized_factor = np.sqrt(np.mean(np.square(mag_increments)))\n",
    "    else:\n",
    "        w_size = interval_of_averaging // tau # window size\n",
    "        # logger.debug(f\"Window size: {w_size}\")\n",
    "        mag_increments_square = np.square(mag_increments)\n",
    "        r = mag_increments_square.rolling(time=w_size, center=True)\n",
    "        normalized_factor = np.sqrt((r.sum() - mag_increments_square)/(w_size-1))\n",
    "        \n",
    "    # logger.info(f\"Normalized factor: {normalized_factor}\")\n",
    "    PVI_series =  mag_increments / normalized_factor\n",
    "    if 'units' in PVI_series.attrs:\n",
    "        del PVI_series.attrs['units']\n",
    "    return PVI_series.rename('PVI')\n",
    "\n",
    "def PVI_map(vec, tau_range, resample_frequency=None):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        vec (_type_): _description_\n",
    "    \"\"\"\n",
    "    if resample_frequency == None:\n",
    "        PVI_series = xr.concat([calculate_PVI_xr(vec, tau) for tau in tau_range], dim='tau')\n",
    "    else:\n",
    "        PVI_series = xr.concat([calculate_PVI_xr(vec, tau, resample_frequency) for tau in tau_range], dim='tau')\n",
    "    PVI_series.attrs[\"long_name\"] = \"PVI\"\n",
    "    return PVI_series.assign_coords({'tau': tau_range})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_PVI_xr(data_array,4).hvplot()\n",
    "calculate_PVI_xr(juno_fgm_b,4).hvplot() * calculate_PVI_xr(juno_fgm_b, 4, interval_of_averaging=16).hvplot() * calculate_PVI_xr(juno_fgm_b, 32, interval_of_averaging=96).hvplot() + juno_fgm_b.hvplot(x='time', by='v_dim')\n",
    "# calculate_PVI_xr(data_array,4).hvplot() + data_array.hvplot(x='time', by='v_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_PVI_xr(juno_fgm_b, 16, interval_of_averaging=48).hvplot()*calculate_PVI_xr(juno_fgm_b, 32, interval_of_averaging=96).hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tau = 32\n",
    "\n",
    "pvi = calculate_PVI_xr(juno_fgm_b, tau, interval_of_averaging=3*tau)\n",
    "pvi_selected = pvi.where(pvi > 2).dropna(dim='time')\n",
    "logger.info(f'{pvi_selected.to_numpy()}')\n",
    "logger.info(f'{pvi_selected.time.to_numpy()}')\n",
    "\n",
    "for temp in pvi_selected:\n",
    "    time = temp.time\n",
    "    temp_tstart = time - pd.Timedelta(3/2*tau, unit='s')\n",
    "    tend = time + pd.Timedelta(3/2*tau, unit='s')\n",
    "    juno_fgm_b.sel(time=slice(temp_tstart, tend)).plot.line(x=\"time\", figure=plt.figure())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_range = range(4,60,4)\n",
    "pvi = PVI_map(data_array, tau_range, tau_range[0]/2)\n",
    "pvi = pvi.where(pvi > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvi.sel(time=slice('2012-05-01T00','2012-05-01T01')).hvplot.quadmesh(x=\"time\", y=\"tau\", ) + data_array.sel(time=slice('2012-05-01T00','2012-05-01T01')).hvplot(x='time', by='v_dim')\n",
    "# calculate_PVI_xr(data_array,4).hvplot() + data_array.hvplot(x='time', by='v_dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvi = calculate_PVI_xr(data_array,4)\n",
    "# select pvi > 3 \n",
    "pvi = pvi.where(pvi > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvi.hvplot(by=\"tau\") * pvi.hvplot.scatter(by=\"tau\") + data_array.hvplot(x='time', by='v_dim')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
