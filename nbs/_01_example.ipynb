{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Finding magnetic discontinuities in Juno's magnetometer data\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: import all the packages needed for the project\n",
    "\n",
    "from ids_finder.utils import *\n",
    "from ids_finder.core import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.test import *\n",
    "\n",
    "import polars as pl\n",
    "import xarray as xr\n",
    "try:\n",
    "    import modin.pandas as pd\n",
    "    import modin.pandas as mpd\n",
    "except ImportError:\n",
    "    import pandas as pd\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "from xarray_einstats import linalg\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "import pytplot\n",
    "from pytplot import timebar\n",
    "from pytplot import get_data, store_data, tplot, split_vec, join_vec, tplot_options, options, tlimit, highlight, degap\n",
    "\n",
    "import pdpipe as pdp\n",
    "\n",
    "\n",
    "from collections.abc import Callable\n",
    "from pandas import (\n",
    "    DataFrame,\n",
    "    Timestamp,\n",
    ")\n",
    "from xarray.core.dataarray import DataArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacecraft-Solar equatorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate System of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **SE (Solar Equatorial)**\n",
    "    - Code: `se`\n",
    "    - Resampling options: \n",
    "        - Number of seconds (1 or 60): `se_rN[N]s`\n",
    "        - Resampled 1 hour: `se_r1h`\n",
    "\n",
    "2. **PC (Planetocentric)**\n",
    "    - Code: `pc`\n",
    "    - Resampling options: \n",
    "        - Number of seconds (1 or 60): `pc_rN[N]s`\n",
    "        \n",
    "3. **SS (Sun-State)**\n",
    "    - Code: `ss`\n",
    "    - Resampling options: \n",
    "        - Number of seconds (1 or 60): `ss_rN[N]s`\n",
    "        \n",
    "4. **PL (Payload)**\n",
    "    - Code: `pl`\n",
    "    - Resampling options: \n",
    "        - Number of seconds (1 or 60): `pl_rN[N]s`\n",
    "\n",
    "\n",
    "```txt\n",
    "------------------------------------------------------------------------------\n",
    "Juno Mission Phases                                                           \n",
    "------------------------------------------------------------------------------\n",
    "Start       Mission                                                           \n",
    "Date        Phase                                                             \n",
    "==============================================================================\n",
    "2011-08-05  Launch                                                            \n",
    "2011-08-08  Inner Cruise 1                                                    \n",
    "2011-10-10  Inner Cruise 2                                                    \n",
    "2013-05-28  Inner Cruise 3                                                    \n",
    "2013-11-05  Quiet Cruise                                                      \n",
    "2016-01-05  Jupiter Approach                                                  \n",
    "2016-06-30  Jupiter Orbital Insertion                                         \n",
    "2016-07-05  Capture Orbit                                                     \n",
    "2016-10-19  Period Reduction Maneuver                                         \n",
    "2016-10-20  Orbits 1-2                                                        \n",
    "2016-11-09  Science Orbits                                                    \n",
    "2017-10-11  Deorbit\n",
    "```\n",
    "\n",
    "```txt\n",
    "File Naming Convention                                                        \n",
    "==============================================================================\n",
    "Convention:                                                                   \n",
    "   fgm_jno_LL_CCYYDDDxx_vVV.ext                                               \n",
    "Where:                                                                        \n",
    "   fgm - Fluxgate Magnetometer three character instrument abbreviation        \n",
    "   jno - Juno                                                                 \n",
    "    LL - CODMAC Data level, for example, l3 for level 3                       \n",
    "    CC - The century portion of a date, 20                                    \n",
    "    YY - The year of century portion of a date, 00-99                         \n",
    "   DDD - The day of year, 001-366                                             \n",
    "    xx - Coordinate system of data (se = Solar equatorial, ser = Solar        \n",
    "         equatorial resampled, pc = Planetocentric, ss = Sun-State,           \n",
    "         pl = Payload)                                                        \n",
    "     v - separator to denote Version number                                   \n",
    "    VV - version                                                              \n",
    "   ext - file extension (sts = Standard Time Series (ASCII) file, lbl = Label \n",
    "         file)                                                                \n",
    "Example:                                                                      \n",
    "   fgm_jno_l3_2014055se_v00.sts    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds_dir = \"https://pds-ppi.igpp.ucla.edu/data\"\n",
    "\n",
    "possible_coords = [\"se\", \"ser\", \"pc\", \"ss\", \"pl\"]\n",
    "possible_exts = [\"sts\", \"lbl\"]\n",
    "possible_data_rates = [\"1s\", \"1min\", \"1h\"]\n",
    "\n",
    "juno_ss_config = {\n",
    "    \"DATA_SET_ID\": \"JNO-SS-3-FGM-CAL-V1.0\",\n",
    "    \"FILE_SPECIFICATION_NAME\": \"INDEX/INDEX.LBL\",\n",
    "}\n",
    "\n",
    "juno_j_config = {\n",
    "    \"DATA_SET_ID\": \"JNO-J-3-FGM-CAL-V1.0\",\n",
    "    \"FILE_SPECIFICATION_NAME\": \"INDEX/INDEX.LBL\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def download_and_read_lbl_file(config, index_table=False):\n",
    "    \"\"\"Download and read file for each config.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The data read from the file.\n",
    "    \"\"\"\n",
    "    # BUG: index file is not formatted properly according to `lbl` file, so can not be used with `pdr` for.\n",
    "    # ValueError: time data \"282T00:00:31.130,2019\" doesn't match format \"%Y-%jT%H:%M:%S.%f\", at position 3553. You might want to try:\n",
    "    # - passing `format` if your strings have a consistent format;\n",
    "    # - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
    "    # - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
    "\n",
    "    local_dir = os.path.join(os.environ[\"HOME\"], \"juno\", config[\"DATA_SET_ID\"])\n",
    "    base_url = f\"{pds_dir}/{config['DATA_SET_ID']}\"\n",
    "\n",
    "    lbl_fn = config[\"FILE_SPECIFICATION_NAME\"]\n",
    "\n",
    "    if not index_table:\n",
    "        parquet_fn = lbl_fn.replace(\"lbl\", \"parquet\")\n",
    "        parquet_fp = os.path.join(local_dir, parquet_fn)\n",
    "        if os.path.exists(parquet_fp):\n",
    "            return pandas.read_parquet(os.path.join(local_dir, parquet_fn))\n",
    "\n",
    "    lbl_file_url = f\"{base_url}/{lbl_fn}\"\n",
    "    lbl_fp = download_file(lbl_file_url, local_dir, lbl_fn)\n",
    "    logger.debug(f\"Reading {lbl_fp}\")\n",
    "\n",
    "    if index_table:\n",
    "        tab_fn = lbl_fn.replace(\"LBL\", \"TAB\")\n",
    "        tab_fp = download_file(f\"{base_url}/{tab_fn}\", local_dir, tab_fn)\n",
    "        tab_index = pandas.read_csv(tab_fp, delimiter=\",\", quotechar='\"')\n",
    "        tab_index.columns = tab_index.columns.str.replace(\" \", \"\")\n",
    "        return tab_index\n",
    "    else:\n",
    "        sts_fn = lbl_fn.replace(\"lbl\", \"sts\")\n",
    "        download_file(f\"{base_url}/{sts_fn}\", local_dir, sts_fn)\n",
    "        return pdr.read(lbl_fp).TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-09-23 10:04:08.643\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mdownload_and_read_lbl_file\u001b[0m:\u001b[36m27\u001b[0m - \u001b[34m\u001b[1mReading /Users/zijin/juno/JNO-SS-3-FGM-CAL-V1.0/INDEX/INDEX.LBL\u001b[0m\n",
      "\u001b[32m2023-09-23 10:04:08.665\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mdownload_and_read_lbl_file\u001b[0m:\u001b[36m27\u001b[0m - \u001b[34m\u001b[1mReading /Users/zijin/juno/JNO-J-3-FGM-CAL-V1.0/INDEX/INDEX.LBL\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "jno_ss_index = download_and_read_lbl_file(juno_ss_config, index_table=True)\n",
    "jno_j_index = download_and_read_lbl_file(juno_j_config, index_table=True)\n",
    "\n",
    "_index_time_format = \"%Y-%jT%H:%M:%S.%f\"\n",
    "\n",
    "jno_pipeline = pdp.PdPipeline(\n",
    "    [\n",
    "        pdp.ColDrop([\"PRODUCT_ID\", \"CR_DATE\", \"PRODUCT_LABEL_MD5CHECKSUM\"]),\n",
    "        pdp.ApplyByCols(\"SID\", str.rstrip),\n",
    "        pdp.ApplyByCols(\"FILE_SPECIFICATION_NAME\", str.rstrip),\n",
    "        pdp.ColByFrameFunc(\n",
    "            \"START_TIME\",\n",
    "            lambda df: pandas.to_datetime(df[\"START_TIME\"], format=_index_time_format),\n",
    "        ),\n",
    "        pdp.ColByFrameFunc(\n",
    "            \"STOP_TIME\",\n",
    "            lambda df: pandas.to_datetime(df[\"STOP_TIME\"], format=_index_time_format),\n",
    "        ),\n",
    "        # pdp.ApplyByCols(['START_TIME', 'STOP_TIME'], pandas.to_datetime, format=_index_time_format), # NOTE: This is slow\n",
    "    ]\n",
    ")\n",
    "\n",
    "jno_ss_index = jno_pipeline(jno_ss_index)\n",
    "jno_j_index = jno_pipeline(jno_j_index)\n",
    "\n",
    "index_df = pandas.concat(\n",
    "    [jno_ss_index, jno_j_index], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting date: 2011-08-25\n",
      "Ending date: 2016-06-29\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "starting_date = jno_ss_index['START_TIME'].min().date()\n",
    "ending_date = jno_ss_index['STOP_TIME'].max().date()\n",
    "\n",
    "print(f\"Starting date: {starting_date}\")\n",
    "print(f\"Ending date: {ending_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following days are missing\n",
      "(#251) ['2012-04-20','2012-04-21','2012-04-22','2012-04-23','2012-04-24','2012-05-15','2012-06-15','2012-07-04','2012-07-05','2012-07-06'...]\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "available_dates = pandas.concat([jno_ss_index['START_TIME'].dt.date, jno_ss_index['STOP_TIME'].dt.date]).unique()\n",
    "full_year_range = pandas.date_range(start=starting_date, end=ending_date)\n",
    "\n",
    "missing_dates = full_year_range[~full_year_range.isin(available_dates)]\n",
    "\n",
    "if len(missing_dates) == 0:\n",
    "    print(f\"No days are missing.\")\n",
    "else:\n",
    "    print(f\"The following days are missing\")\n",
    "    print(coll_repr(missing_dates.map(lambda x: x.strftime(\"%Y-%m-%d\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget -r --no-parent --no-clobber 'https://pds-ppi.igpp.ucla.edu/data/JNO-SS-3-FGM-CAL-V1.0/DATA/CRUISE/SE/1SEC/'\n",
    "# aria2c -x 16 -s 16 'https://pds-ppi.igpp.ucla.edu/ditdos/download?id=pds://PPI/JNO-SS-3-FGM-CAL-V1.0/DATA/CRUISE/SE/1SEC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 day of data resampled by 1 sec is about 12 MB.\n",
    "\n",
    "So 1 year of data is about 4 GB, and 6 years of JUNO Cruise data is about 24 GB.\n",
    "\n",
    "Downloading rate is about 250 KB/s, so it will take about 3 days to download all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to download: 126.53 hours\n",
      "Disk space required: 113.88 GB\n",
      "Time to process: 36.50 hours\n"
     ]
    }
   ],
   "source": [
    "num_of_files = 6*365\n",
    "jno_file_size = 12e3\n",
    "thm_file_size = 40e3\n",
    "files_size = jno_file_size + thm_file_size\n",
    "downloading_rate = 250\n",
    "processing_rate = 1/60\n",
    "\n",
    "time_to_download = num_of_files * files_size / downloading_rate / 60 / 60\n",
    "space_required = num_of_files * files_size / 1e6\n",
    "time_to_process = num_of_files / processing_rate / 60 / 60\n",
    "\n",
    "print(f\"Time to download: {time_to_download:.2f} hours\")\n",
    "print(f\"Disk space required: {space_required:.2f} GB\")\n",
    "print(f\"Time to process: {time_to_process:.2f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all files from `lbl` to `parquet` for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: Convert data from `lbl` to `parquet` format\n",
    "def lbl2parquet(src: Path, dest: Path) -> None:\n",
    "    df = pdr.read(src).TABLE\n",
    "    df.to_parquet(dest)\n",
    "\n",
    "\n",
    "def convert_file(\n",
    "    file_path: Path, target_format: str, conversion_func: Callable, check_exist=True\n",
    ") -> None:\n",
    "    target_suffix = (\n",
    "        target_format if target_format.startswith(\".\") else f\".{target_format}\"\n",
    "    )\n",
    "    target_file = file_path.with_suffix(target_suffix)\n",
    "\n",
    "    if check_exist and target_file.exists():\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        conversion_func(file_path, target_file)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error converting {file_path} to {target_file}: {e}\")\n",
    "        return False\n",
    "\n",
    "@startthread\n",
    "def convert_files():\n",
    "    format_from = \"lbl\"\n",
    "    format_to = \"parquet\"\n",
    "    local_dir = Path.home() / \"data/juno\"\n",
    "    pattern = f\"**/*.{format_from}\"\n",
    "    convert_func = lbl2parquet\n",
    "    for file in local_dir.glob(pattern):\n",
    "        convert_file(file, format_to, convert_func)\n",
    "    logger.info(\"Done converting files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all files with extension\n",
    "# find . -type f -name '*.parquet' -delete\n",
    "# find . -type f -name '*.orc' -delete\n",
    "# find . -type f -name '*.lbl' -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-09-23 10:04:09.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mconvert_files\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mDone converting files\u001b[0m\n",
      "\u001b[32m2023-09-23 10:04:09.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_batch_pre_process\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mFile ../data/jno_2011.parquet exists. Skipping\u001b[0m\n",
      "\u001b[32m2023-09-23 10:04:09.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_batch_pre_process\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mFile ../data/jno_2012.parquet exists. Skipping\u001b[0m\n",
      "\u001b[32m2023-09-23 10:04:09.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_batch_pre_process\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mFile ../data/jno_2013.parquet exists. Skipping\u001b[0m\n",
      "\u001b[32m2023-09-23 10:04:09.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_batch_pre_process\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mFile ../data/jno_2014.parquet exists. Skipping\u001b[0m\n",
      "\u001b[32m2023-09-23 10:04:09.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_batch_pre_process\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mFile ../data/jno_2015.parquet exists. Skipping\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-09-23 10:04:09.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_batch_pre_process\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mFile ../data/jno_2016.parquet exists. Skipping\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def _batch_pre_process(year, force=False):\n",
    "    trange = [f\"{year}-01-01\", f\"{year+1}-01-01T01\"]  # having some overlap\n",
    "    dir_path = Path.home() /  \"data/juno/JNO-SS-3-FGM-CAL-V1.0/\"\n",
    "    pattern = \"**/*.parquet\"\n",
    "    data = dir_path / pattern\n",
    "    \n",
    "    output = Path(f\"../data/jno_{year}.parquet\")\n",
    "    output.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if os.path.exists(output) and not force:\n",
    "        logger.info(f\"File {output} exists. Skipping\")\n",
    "        return output\n",
    "    logger.info(f\"Preprocessing data for year {year}\")\n",
    "    \n",
    "    lazy_df = pl.scan_parquet(data)\n",
    "    temp_df = (\n",
    "        lazy_df.filter(\n",
    "            pl.col(\"time\").is_between(pd.Timestamp(trange[0]), pd.Timestamp(trange[1])),\n",
    "        )\n",
    "        .sort(\n",
    "            \"time\"\n",
    "        )  # needed for `compute_index_std` to work properly as `group_by_dynamic` requires the data to be sorted\n",
    "        .filter(\n",
    "            pl.col(\n",
    "                \"time\"\n",
    "            ).is_first_distinct()  # remove duplicate time values for xarray to select data properly, though significantly slows down the computation\n",
    "        )\n",
    "        .rename({\"BX SE\": \"BX\", \"BY SE\": \"BY\", \"BZ SE\": \"BZ\"})\n",
    "    )\n",
    "    temp_df.collect().write_parquet(output)\n",
    "    return output\n",
    "\n",
    "@startthread\n",
    "def batch_pre_process():\n",
    "    starting_year = starting_date.year\n",
    "    ending_year = ending_date.year\n",
    "\n",
    "    for year in range(starting_year, ending_year+1):\n",
    "        _batch_pre_process(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Beforerr/planet/blob/master/ids_finder/core.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### process_candidates\n",
       "\n",
       ">      process_candidates\n",
       ">                          (candidates:modin.pandas.dataframe.DataFrame|pandas.c\n",
       ">                          ore.frame.DataFrame,\n",
       ">                          sat_fgm:xarray.core.dataarray.DataArray,\n",
       ">                          sat_state:xarray.core.dataarray.DataArray,\n",
       ">                          data_resolution:datetime.timedelta)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| candidates | modin.pandas.dataframe.DataFrame \\| pandas.core.frame.DataFrame | potential candidates DataFrame |\n",
       "| sat_fgm | DataArray | satellite FGM data |\n",
       "| sat_state | DataArray | satellite state data |\n",
       "| data_resolution | timedelta | time resolution of the data |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Beforerr/planet/blob/master/ids_finder/core.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### process_candidates\n",
       "\n",
       ">      process_candidates\n",
       ">                          (candidates:modin.pandas.dataframe.DataFrame|pandas.c\n",
       ">                          ore.frame.DataFrame,\n",
       ">                          sat_fgm:xarray.core.dataarray.DataArray,\n",
       ">                          sat_state:xarray.core.dataarray.DataArray,\n",
       ">                          data_resolution:datetime.timedelta)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| candidates | modin.pandas.dataframe.DataFrame \\| pandas.core.frame.DataFrame | potential candidates DataFrame |\n",
       "| sat_fgm | DataArray | satellite FGM data |\n",
       "| sat_state | DataArray | satellite state data |\n",
       "| data_resolution | timedelta | time resolution of the data |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(process_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[32m2023-09-23 10:16:25.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbatch_process\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mSkipping 2011 as the output file already exists.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-09-23 10:16:25.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbatch_process\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mSkipping 2012 as the output file already exists.\u001b[0m\n",
      "\u001b[32m2023-09-23 10:16:25.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbatch_process\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mSkipping 2013 as the output file already exists.\u001b[0m\n",
      "\u001b[32m2023-09-23 10:16:25.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbatch_process\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mSkipping 2014 as the output file already exists.\u001b[0m\n",
      "\u001b[32m2023-09-23 10:16:25.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbatch_process\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mSkipping 2015 as the output file already exists.\u001b[0m\n",
      "\u001b[32m2023-09-23 10:16:25.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbatch_process\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mSkipping 2016 as the output file already exists.\u001b[0m\n",
      "100%|██████████| 6/6 [00:00<00:00, 1551.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sat = 'jno'\n",
    "coord = 'se'\n",
    "tau = timedelta(seconds=60)\n",
    "data_resolution = timedelta(seconds=1)\n",
    "\n",
    "@startthread\n",
    "def batch_process():\n",
    "    for year in tqdm(range(starting_date.year, ending_date.year+1)):\n",
    "        files = f'../data/{sat}_{year}.parquet'\n",
    "        output = f'../data/{sat}_candidates_{year}_tau_{tau.seconds}.parquet'\n",
    "        \n",
    "        if os.path.exists(output):\n",
    "            logger.info(f\"Skipping {year} as the output file already exists.\")\n",
    "            continue\n",
    "\n",
    "        data = pl.scan_parquet(files).set_sorted('time').collect()\n",
    "        sat_fgm = df2ts(data, [\"BX\", \"BY\", \"BZ\"], attrs={\"coordinate_system\": coord, \"units\": \"nT\"})\n",
    "        sat_state = df2ts(data, [\"X\", \"Y\", \"Z\"], attrs={\"coordinate_system\": coord, \"units\": \"km\"})\n",
    "\n",
    "        indices = compute_indices(data, tau)\n",
    "        # filter condition\n",
    "        sparse_num = tau / data_resolution // 3\n",
    "        filter_condition = get_ID_filter_condition(sparse_num = sparse_num)\n",
    "\n",
    "        candidates_pl = indices.filter(filter_condition).with_columns(pl_format_time(tau))\n",
    "        candidates = convert_to_dataframe(candidates_pl)\n",
    "        \n",
    "        ids = process_candidates(candidates, sat_fgm, sat_state, data_resolution)\n",
    "        \n",
    "        if isinstance(ids, mpd.DataFrame):\n",
    "            ids._to_pandas().to_parquet(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THEMIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]21-Sep-23 03:05:26: UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "\n",
      "Distributing Dataframe: 100%██████████ Elapsed time: 00:00, estimated remaining time: 00:00\n",
      "  0%|          | 0/6 [01:39<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/zijin/projects/planet/main.ipynb Cell 72\u001b[0m line \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m filter_condition \u001b[39m=\u001b[39m get_ID_filter_condition(sparse_num \u001b[39m=\u001b[39m sparse_num)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m candidates \u001b[39m=\u001b[39m indices\u001b[39m.\u001b[39mfilter(filter_condition)\u001b[39m.\u001b[39mwith_columns(pl_format_time(tau))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m ids \u001b[39m=\u001b[39m process_candidates(candidates, sat_fgm, sat_state)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m df \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mDataFrame(ids)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m df\u001b[39m.\u001b[39mto_parquet(output)\n",
      "\u001b[1;32m/Users/zijin/projects/planet/main.ipynb Cell 72\u001b[0m line \u001b[0;36mprocess_candidates\u001b[0;34m(candidates, sat_fgm, sat_state)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m pdp_assign_coordinates \u001b[39m=\u001b[39m \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     ApplyToRows(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         \u001b[39mlambda\u001b[39;00m candidate: get_candidate_location(candidate, sat_state),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         func_desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39massigning coordinates\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# TODO: can we use `pdp.ColByFrameFunc` here?\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# fmt: on\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m candidates \u001b[39m=\u001b[39m pdp_calc_duration\u001b[39m.\u001b[39;49mapply(candidates)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# calibrate duration\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m temp_candidates \u001b[39m=\u001b[39m candidates\u001b[39m.\u001b[39mloc[\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mlambda\u001b[39;00m df: df[\u001b[39m\"\u001b[39m\u001b[39md_tstart\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39misnull() \u001b[39m|\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39md_tstop\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39misnull()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m ]\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/pdpipe/core.py:1282\u001b[0m, in \u001b[0;36mPdPipeline.apply\u001b[0;34m(self, X, y, exraise, verbose, time, fit_context, application_context)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(\n\u001b[1;32m   1274\u001b[0m         X,\n\u001b[1;32m   1275\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1279\u001b[0m         application_context\u001b[39m=\u001b[39mapplication_context,\n\u001b[1;32m   1280\u001b[0m     )\n\u001b[1;32m   1281\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m-> 1282\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_transform(\n\u001b[1;32m   1283\u001b[0m     X,\n\u001b[1;32m   1284\u001b[0m     y,\n\u001b[1;32m   1285\u001b[0m     exraise\u001b[39m=\u001b[39;49mexraise,\n\u001b[1;32m   1286\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1287\u001b[0m     time\u001b[39m=\u001b[39;49mtime,\n\u001b[1;32m   1288\u001b[0m     fit_context\u001b[39m=\u001b[39;49mfit_context,\n\u001b[1;32m   1289\u001b[0m     application_context\u001b[39m=\u001b[39;49mapplication_context,\n\u001b[1;32m   1290\u001b[0m )\n\u001b[1;32m   1291\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/pdpipe/core.py:1424\u001b[0m, in \u001b[0;36mPdPipeline.fit_transform\u001b[0;34m(self, X, y, exraise, verbose, time, fit_context, application_context)\u001b[0m\n\u001b[1;32m   1421\u001b[0m     stage\u001b[39m.\u001b[39mapplication_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapplication_context\n\u001b[1;32m   1422\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_dynamics(stage, inter_X, inter_y)\n\u001b[0;32m-> 1424\u001b[0m     inter_X \u001b[39m=\u001b[39m stage\u001b[39m.\u001b[39;49mfit_transform(\n\u001b[1;32m   1425\u001b[0m         X\u001b[39m=\u001b[39;49minter_X,\n\u001b[1;32m   1426\u001b[0m         y\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1427\u001b[0m         exraise\u001b[39m=\u001b[39;49mexraise,\n\u001b[1;32m   1428\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1429\u001b[0m     )\n\u001b[1;32m   1430\u001b[0m     stage\u001b[39m.\u001b[39mapplication_context \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/pdpipe/core.py:701\u001b[0m, in \u001b[0;36mPdPipelineStage.fit_transform\u001b[0;34m(self, X, y, exraise, verbose)\u001b[0m\n\u001b[1;32m    698\u001b[0m     res_X, res_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_Xy(\n\u001b[1;32m    699\u001b[0m         X, y, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[1;32m    700\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 701\u001b[0m     res_X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(X, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    702\u001b[0m     res_y \u001b[39m=\u001b[39m y\n\u001b[1;32m    703\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_fitted \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/pdpipe/core.py:489\u001b[0m, in \u001b[0;36mPdPipelineStage._fit_transform\u001b[0;34m(self, X, verbose)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_transform\u001b[39m(\n\u001b[1;32m    471\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    472\u001b[0m     X: pandas\u001b[39m.\u001b[39mDataFrame,\n\u001b[1;32m    473\u001b[0m     verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    474\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pandas\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m    475\u001b[0m     \u001b[39m\"\"\"Fits this stage and transforms the input dataframe.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \n\u001b[1;32m    477\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39m        The transformed dataframe.\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X, verbose\u001b[39m=\u001b[39;49mverbose)\n",
      "\u001b[1;32m/Users/zijin/projects/planet/main.ipynb Cell 72\u001b[0m line \u001b[0;36mApplyToRows._transform\u001b[0;34m(self, X, verbose)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform\u001b[39m(\u001b[39mself\u001b[39m, X, verbose):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     new_cols \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mapply(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(new_cols, pd\u001b[39m.\u001b[39mSeries):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zijin/projects/planet/main.ipynb#Y130sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         loc \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X\u001b[39m.\u001b[39mcolumns)\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/logging/logger_decorator.py:128\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m    131\u001b[0m logger_level \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(logger, log_level)\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/pandas/dataframe.py:419\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39m# the 'else' branch also handles 'result_type == \"expand\"' since it makes the output type\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39m# depend on the `func` result (Series for a scalar, DataFrame for list-like)\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     reduced_index \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mIndex([MODIN_UNNAMED_SERIES_LABEL])\n\u001b[0;32m--> 419\u001b[0m     \u001b[39mif\u001b[39;00m query_compiler\u001b[39m.\u001b[39;49mget_axis(axis)\u001b[39m.\u001b[39mequals(\n\u001b[1;32m    420\u001b[0m         reduced_index\n\u001b[1;32m    421\u001b[0m     ) \u001b[39mor\u001b[39;00m query_compiler\u001b[39m.\u001b[39mget_axis(axis \u001b[39m^\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mequals(reduced_index):\n\u001b[1;32m    422\u001b[0m         output_type \u001b[39m=\u001b[39m Series\n\u001b[1;32m    423\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/logging/logger_decorator.py:128\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m    131\u001b[0m logger_level \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(logger, log_level)\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/core/storage_formats/base/query_compiler.py:4080\u001b[0m, in \u001b[0;36mBaseQueryCompiler.get_axis\u001b[0;34m(self, axis)\u001b[0m\n\u001b[1;32m   4066\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_axis\u001b[39m(\u001b[39mself\u001b[39m, axis):\n\u001b[1;32m   4067\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4068\u001b[0m \u001b[39m    Return index labels of the specified axis.\u001b[39;00m\n\u001b[1;32m   4069\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4078\u001b[0m \u001b[39m    pandas.Index\u001b[39;00m\n\u001b[1;32m   4079\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4080\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/core/storage_formats/pandas/query_compiler.py:90\u001b[0m, in \u001b[0;36m_get_axis.<locals>.<lambda>\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m \u001b[39mself\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modin_frame\u001b[39m.\u001b[39mindex\n\u001b[1;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m \u001b[39mself\u001b[39m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_modin_frame\u001b[39m.\u001b[39;49mcolumns\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:544\u001b[0m, in \u001b[0;36mPandasDataframe._get_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    542\u001b[0m     columns, column_widths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_columns_cache\u001b[39m.\u001b[39mget(return_lengths\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    543\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 544\u001b[0m     columns, column_widths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_axis_labels_and_lengths(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    545\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_columns_cache(columns)\n\u001b[1;32m    546\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_column_widths_cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/logging/logger_decorator.py:128\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m    131\u001b[0m logger_level \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(logger, log_level)\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/core/dataframe/pandas/dataframe/dataframe.py:630\u001b[0m, in \u001b[0;36mPandasDataframe._compute_axis_labels_and_lengths\u001b[0;34m(self, axis, partitions)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m partitions \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     partitions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_partitions\n\u001b[0;32m--> 630\u001b[0m new_index, internal_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partition_mgr_cls\u001b[39m.\u001b[39;49mget_indices(axis, partitions)\n\u001b[1;32m    631\u001b[0m \u001b[39mreturn\u001b[39;00m new_index, \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlen\u001b[39m, internal_idx))\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/logging/logger_decorator.py:128\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m    131\u001b[0m logger_level \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(logger, log_level)\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:933\u001b[0m, in \u001b[0;36mPandasDataframePartitionManager.get_indices\u001b[0;34m(cls, axis, partitions, index_func)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target):\n\u001b[1;32m    932\u001b[0m     new_idx \u001b[39m=\u001b[39m [idx\u001b[39m.\u001b[39mapply(func) \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m target[\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 933\u001b[0m     new_idx \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_objects_from_partitions(new_idx)\n\u001b[1;32m    934\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m     new_idx \u001b[39m=\u001b[39m [pandas\u001b[39m.\u001b[39mIndex([])]\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/logging/logger_decorator.py:128\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mCompute function with logging if Modin logging is enabled.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mAny\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m LogMode\u001b[39m.\u001b[39mget() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdisable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m obj(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m logger \u001b[39m=\u001b[39m get_logger()\n\u001b[1;32m    131\u001b[0m logger_level \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(logger, log_level)\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/core/dataframe/pandas/partitioning/partition_manager.py:874\u001b[0m, in \u001b[0;36mPandasDataframePartitionManager.get_objects_from_partitions\u001b[0;34m(cls, partitions)\u001b[0m\n\u001b[1;32m    870\u001b[0m             partitions[idx] \u001b[39m=\u001b[39m part\u001b[39m.\u001b[39mforce_materialization()\n\u001b[1;32m    871\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    872\u001b[0m         [\u001b[39mlen\u001b[39m(partition\u001b[39m.\u001b[39mlist_of_blocks) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m partition \u001b[39min\u001b[39;00m partitions]\n\u001b[1;32m    873\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mImplementation assumes that each partition contains a single block.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 874\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_execution_wrapper\u001b[39m.\u001b[39;49mmaterialize(\n\u001b[1;32m    875\u001b[0m         [partition\u001b[39m.\u001b[39;49mlist_of_blocks[\u001b[39m0\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m partition \u001b[39min\u001b[39;49;00m partitions]\n\u001b[1;32m    876\u001b[0m     )\n\u001b[1;32m    877\u001b[0m \u001b[39mreturn\u001b[39;00m [partition\u001b[39m.\u001b[39mget() \u001b[39mfor\u001b[39;00m partition \u001b[39min\u001b[39;00m partitions]\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/modin/core/execution/ray/common/engine_wrapper.py:92\u001b[0m, in \u001b[0;36mRayWrapper.materialize\u001b[0;34m(cls, obj_id)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmaterialize\u001b[39m(\u001b[39mcls\u001b[39m, obj_id):\n\u001b[1;32m     79\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39m    Get the value of object from the Plasma store.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m        Whatever was identified by `obj_id`.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mreturn\u001b[39;00m ray\u001b[39m.\u001b[39;49mget(obj_id)\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:24\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mauto_init_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     23\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 24\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/ray/_private/worker.py:2541\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2536\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2537\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject_refs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must either be an ObjectRef or a list of ObjectRefs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2538\u001b[0m     )\n\u001b[1;32m   2540\u001b[0m \u001b[39m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 2541\u001b[0m values, debugger_breakpoint \u001b[39m=\u001b[39m worker\u001b[39m.\u001b[39;49mget_objects(object_refs, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   2542\u001b[0m \u001b[39mfor\u001b[39;00m i, value \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(values):\n\u001b[1;32m   2543\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[0;32m~/mambaforge/envs/cool_planet/lib/python3.10/site-packages/ray/_private/worker.py:756\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    751\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to call `get` on the value \u001b[39m\u001b[39m{\u001b[39;00mobject_ref\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    752\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwhich is not an ray.ObjectRef.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    753\u001b[0m         )\n\u001b[1;32m    755\u001b[0m timeout_ms \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m) \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m--> 756\u001b[0m data_metadata_pairs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcore_worker\u001b[39m.\u001b[39;49mget_objects(\n\u001b[1;32m    757\u001b[0m     object_refs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_task_id, timeout_ms\n\u001b[1;32m    758\u001b[0m )\n\u001b[1;32m    759\u001b[0m debugger_breakpoint \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    760\u001b[0m \u001b[39mfor\u001b[39;00m data, metadata \u001b[39min\u001b[39;00m data_metadata_pairs:\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3110\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:445\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sat = 'thb'\n",
    "coord = 'gse'\n",
    "tau = timedelta(seconds=60)\n",
    "data_resolution = timedelta(seconds=4)\n",
    "\n",
    "files = f'data/{sat}_fgs_{coord}.parquet'\n",
    "output = f'data/{sat}_candidates_{year}_tau_{tau.seconds}.parquet'\n",
    "\n",
    "if os.path.exists(output):\n",
    "    logger.info(f\"Skipping {year} as the output file already exists.\")\n",
    "    continue\n",
    "\n",
    "data = pl.scan_parquet(files).set_sorted('time').collect()\n",
    "sat_fgm = df2ts(data, [\"BX\", \"BY\", \"BZ\"], attrs={\"coordinate_system\": coord, \"units\": \"nT\"})\n",
    "sat_state = pandas.read_parquet(f'data/{sat}_state.parquet')\n",
    "\n",
    "indices = compute_indices(data, tau)\n",
    "# filter condition\n",
    "sparse_num = tau / data_resolution // 3\n",
    "filter_condition = get_ID_filter_condition(sparse_num = sparse_num)\n",
    "\n",
    "candidates = indices.filter(filter_condition).with_columns(pl_format_time(tau))\n",
    "\n",
    "ids = process_candidates(candidates, sat_fgm, sat_state)\n",
    "df = ids.to_pandas()\n",
    "df.to_parquet(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read candidates from files in current directory\n",
    "pattern = 'data/candidates*.parquet'\n",
    "data = Path() / pattern\n",
    "\n",
    "candidates = pl.scan_parquet(data).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(candidates.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting candidates of different types of discontinuities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candidates(candidates, candidate_type='TD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candidates(candidates, candidate_type='RD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candidates(candidates, candidate_type='ED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candidates(candidates, candidate_type='ND')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occurrence rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the occurence rates of different types of ID\n",
    "def occurence_rate(candidates, candidate_type):\n",
    "    return len(candidates[candidates['type'] == candidate_type]) / len(candidates)\n",
    "\n",
    "def time_occurence_rate(candidates):\n",
    "    if len(candidates) <= 1:\n",
    "        return None\n",
    "    else:\n",
    "        return (candidates.iloc[-1]['tstop'] - candidates.iloc[0]['tstart']) / (len(candidates) -1)\n",
    "\n",
    "CANDIDATE_TYPES = ['RD', 'TD', 'ED', 'ND']\n",
    "\n",
    "for candidate_type in CANDIDATE_TYPES:\n",
    "    logger.info(f\"Occurrence rate of {candidate_type}: {occurence_rate(candidates, candidate_type)}\")\n",
    "    logger.info(f\"Time occurrence rate of {candidate_type}: {time_occurence_rate(candidates[candidates['type'] == candidate_type])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp.ColByFrameFunc(\"R\", lambda df: df[['X','Y', 'Z']].apply(np.linalg.norm, axis=1), func_desc='calculating R')(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates.plot(x=\"X\", y=\"d_star\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates.update(pdp_calibrate_duration.apply(temp_candidates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_candidates = get_candidates(candidates, 'RD')\n",
    "temp_candidates = pdp_calc_duration(temp_candidates)\n",
    "temp_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candidates(temp_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test minvar and principal axes vectors\n",
    "test_data = np.array([[1,1,0],[-1,-1,0]])\n",
    "vrot, v, w = minvar(test_data)\n",
    "Vi = v[:,0]\n",
    "print(Vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test minvar_matrix_make\n",
    "in_var_name = \"fgm\"\n",
    "\n",
    "vrot, v, w = minvar(get_data(in_var_name, xarray=True))\n",
    "\n",
    "minvar_matrix_make(in_var_name)\n",
    "tvector_rotate(f'{in_var_name}_mva_mat', in_var_name)\n",
    "(get_data(f\"{in_var_name}_rot\").y==vrot).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_candidates(candidates.loc[lambda _: _['time']=='2012-07-10 02:31:15'])\n",
    "temp_trange = ['2012-07-15 03:44', '2012-07-15 03:47']\n",
    "temp_data = sat_fgm.sel(time=slice(*temp_trange))\n",
    "temp_data.plot.scatter(x='time', hue='v_dim')\n",
    "# temp_data.resample(time=pd.Timedelta(tau, unit='s')).map(calc_vec_std)\n",
    "compute_index_std(temp_data, tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case: neighboring data is missing, causing the calculation of the standard deviation index to be Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case: neighboring data is missing, causing the calculation of the standard deviation index to be Inf.\n",
    "temp_trange = ['2012-07-10 02:30', '2012-07-10 02:32']\n",
    "temp_data = sat_fgm.sel(time=slice(*temp_trange))\n",
    "temp_data.plot.scatter(x='time', hue='v_dim')\n",
    "# temp_data.resample(time=pd.Timedelta(tau, unit='s')).map(calc_vec_std)\n",
    "compute_index_std(temp_data, tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caveats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_candidates(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: Not very accurate for waving magnetic field..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_candidate = {'time': Timestamp('2012-05-01 00:39:12'),\n",
    " 'tstart': Timestamp('2012-05-01 00:38:56'),\n",
    " 'tstop': Timestamp('2012-05-01 00:39:28'),\n",
    " 'i1': 2.891042053414383,\n",
    " 'i2': 2.389699609352786,\n",
    " 'i3': 1.3916002784658887,\n",
    " 'd_star': 0.27143595,\n",
    " 'd_time': Timestamp('2012-05-01 00:39:18.672000'),\n",
    " 'd_tstart': Timestamp('2012-05-01 00:39:14.672000'),\n",
    " 'd_tstop': Timestamp('2012-05-01 00:39:19.671000'),\n",
    "}\n",
    "\n",
    "plot_candidate(temp_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_candidate_data_xr(temp_candidate, neighbor=1)\n",
    "vec_diff = data.differentiate(\"time\", datetime_unit=\"s\", edge_order=2).isel(time=slice(1,-1))\n",
    "vec_diff_mag = linalg.norm(vec_diff, dims='v_dim')\n",
    "vec_diff_mag.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: Small threshold_ratio values will tend to make the duration longer if the duration can be determined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different threshold ratios\n",
    "threshold_ratios = [1/8, 1/4, 0.3, 1/3, 1/2]\n",
    "for threshold_ratio in threshold_ratios:\n",
    "    temp_candidate.update(calc_duration(get_candidate_data_xr(temp_candidate), threshold_ratio=threshold_ratio).to_dict())\n",
    "    plot_candidate(temp_candidate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
